{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0c83ae",
   "metadata": {},
   "source": [
    "# ì°ë§‰ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d54e1b51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting CSV â†’ QUIQ:   0%|                               | 0/18 [00:00<?, ?file/s, reading allergies.csv]\n",
      "  allergies:   0%|                                                                    | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  allergies:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                      | 1/4 [00:00<00:00, 499.98step/s, loaded]\u001b[A\n",
      "  allergies:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 2/4 [00:00<00:00, 666.82step/s, sampled n=111]\u001b[A\n",
      "  allergies:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 3/4 [00:00<00:00, 32.26step/s, converted rows=1443]\u001b[A\n",
      "  allergies: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 38.83step/s, converted rows=1443]\u001b[A\n",
      "  allergies: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 38.83step/s, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ:   6%|â–ˆâ–                     | 1/18 [00:00<00:01,  9.26file/s, reading careplans.csv]\u001b[A\n",
      "  careplans:   0%|                                                                    | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  careplans:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                      | 1/4 [00:00<00:00, 333.30step/s, loaded]\u001b[A\n",
      "  careplans:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 2/4 [00:00<00:00, 499.95step/s, sampled n=359]\u001b[A\n",
      "  careplans:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 3/4 [00:00<00:00, 11.77step/s, sampled n=359]\u001b[A\n",
      "  careplans:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 3/4 [00:00<00:00, 11.77step/s, converted rows=2154]\u001b[A\n",
      "  careplans: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.77step/s, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ:  11%|â–ˆâ–ˆâ–‰                       | 2/18 [00:00<00:03,  4.84file/s, reading claims.csv]\u001b[A\n",
      "  claims:   0%|                                                                       | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  claims:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                         | 1/4 [00:00<00:00, 25.00step/s, loaded]\u001b[A\n",
      "  claims:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 2/4 [00:00<00:00, 48.78step/s, sampled n=10850]\u001b[A\n",
      "  claims:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           | 3/4 [00:17<00:05,  5.99s/step, sampled n=10850]\u001b[A\n",
      "  claims:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 3/4 [00:17<00:05,  5.99s/step, converted rows=314650]\u001b[A\n",
      "  claims: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:18<00:00,  4.34s/step, converted rows=314650]\u001b[A\n",
      "  claims: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:18<00:00,  4.34s/step, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ:  17%|â–ˆâ–ˆâ–          | 3/18 [00:19<02:10,  8.72s/file, reading claims_transactions.csv]\u001b[A\n",
      "  claims_transactions:   0%|                                                          | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  claims_transactions:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                     | 1/4 [00:00<00:01,  2.96step/s]\u001b[A\n",
      "  claims_transactions:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                               | 1/4 [00:00<00:01,  2.96step/s, loaded]\u001b[A\n",
      "  claims_transactions:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 2/4 [00:00<00:00,  2.96step/s, sampled n=96423]\u001b[A\n",
      "  claims_transactions:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 3/4 [02:15<00:50, 50.12s/step, sampled n=96423]\u001b[A\n",
      "  claims_transactions:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 3/4 [02:15<00:50, 50.12s/step, converted rows=2989113]\u001b[A\n",
      "  claims_transactions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:23<00:00, 35.60s/step, converted rows=2989113]\u001b[A\n",
      "  claims_transactions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:23<00:00, 35.60s/step, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 4/18 [02:42<14:27, 61.97s/file, reading conditions.csv]\u001b[A\n",
      "  conditions:   0%|                                                                   | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  conditions:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                      | 1/4 [00:00<00:00, 83.34step/s, loaded]\u001b[A\n",
      "  conditions:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 2/4 [00:00<00:00, 153.85step/s, sampled n=4140]\u001b[A\n",
      "  conditions:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 3/4 [00:01<00:00,  1.74step/s, sampled n=4140]\u001b[A\n",
      "  conditions:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 3/4 [00:01<00:00,  1.74step/s, converted rows=20700]\u001b[A\n",
      "  conditions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.74step/s, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                  | 5/18 [02:44<08:43, 40.28s/file, reading devices.csv]\u001b[A\n",
      "  devices:   0%|                                                                      | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  devices:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                       | 1/4 [00:00<00:00, 249.96step/s, loaded]\u001b[A\n",
      "  devices:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 2/4 [00:00<00:00, 400.07step/s, sampled n=695]\u001b[A\n",
      "  devices:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 3/4 [00:00<00:00,  8.29step/s, sampled n=695]\u001b[A\n",
      "  devices:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 3/4 [00:00<00:00,  8.29step/s, converted rows=3475]\u001b[A\n",
      "  devices: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.29step/s, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 6/18 [02:45<05:20, 26.72s/file, reading encounters.csv]\u001b[A\n",
      "  encounters:   0%|                                                                   | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  encounters:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                      | 1/4 [00:00<00:00, 52.63step/s, loaded]\u001b[A\n",
      "  encounters:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 2/4 [00:00<00:00, 105.27step/s, sampled n=5924]\u001b[A\n",
      "  encounters:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 3/4 [00:04<00:01,  1.35s/step, sampled n=5924]\u001b[A\n",
      "  encounters:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 3/4 [00:04<00:01,  1.35s/step, converted rows=77012]\u001b[A\n",
      "  encounters: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01step/s, converted rows=77012]\u001b[A\n",
      "  encounters: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01step/s, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 7/18 [02:49<03:33, 19.38s/file, reading imaging_studies.csv]\u001b[A\n",
      "  imaging_studies:   0%|                                                              | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  imaging_studies:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                  | 1/4 [00:00<00:00, 40.00step/s, loaded]\u001b[A\n",
      "  imaging_studies:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 2/4 [00:00<00:00, 76.92step/s, sampled n=9071]\u001b[A\n",
      "  imaging_studies:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 3/4 [00:03<00:01,  1.21s/step, sampled n=9071]\u001b[A\n",
      "  imaging_studies:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 3/4 [00:03<00:01,  1.21s/step, converted rows=90710]\u001b[A\n",
      "  imaging_studies: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.09step/s, converted rows=90710]\u001b[A\n",
      "  imaging_studies: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.09step/s, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 8/18 [02:53<02:24, 14.47s/file, reading immunizations.csv]\u001b[A\n",
      "  immunizations:   0%|                                                                | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  immunizations:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                   | 1/4 [00:00<00:00, 200.00step/s, loaded]\u001b[A\n",
      "  immunizations:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 2/4 [00:00<00:00, 333.33step/s, sampled n=1549]\u001b[A\n",
      "  immunizations:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 3/4 [00:00<00:00,  6.11step/s, sampled n=1549]\u001b[A\n",
      "  immunizations:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 3/4 [00:00<00:00,  6.11step/s, converted rows=6196]\u001b[A\n",
      "  immunizations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.11step/s, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 9/18 [02:53<01:30, 10.11s/file, reading medications.csv]\u001b[A\n",
      "  medications:   0%|                                                                  | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  medications:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                    | 1/4 [00:00<00:00, 100.00step/s, loaded]\u001b[A\n",
      "  medications:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 2/4 [00:00<00:00, 181.82step/s, sampled n=4926]\u001b[A\n",
      "  medications:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 3/4 [00:03<00:01,  1.07s/step, sampled n=4926]\u001b[A\n",
      "  medications:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 3/4 [00:03<00:01,  1.07s/step, converted rows=54186]\u001b[A\n",
      "  medications: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.28step/s, converted rows=54186]\u001b[A\n",
      "  medications: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.28step/s, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 10/18 [02:57<01:04,  8.03s/file, reading observations.csv]\u001b[A\n",
      "  observations:   0%|                                                                 | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  observations:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                    | 1/4 [00:00<00:00, 12.05step/s, loaded]\u001b[A\n",
      "  observations:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 2/4 [00:00<00:00, 23.81step/s, sampled n=88156]\u001b[A\n",
      "  observations:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 3/4 [00:00<00:00,  5.57step/s, sampled n=88156]\u001b[A\n",
      "  observations:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 3/4 [00:00<00:00,  5.57step/s, converted rows=264468]\u001b[A\n",
      "  observations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.55step/s, converted rows=264468]\u001b[A\n",
      "  observations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.55step/s, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 11/18 [02:58<00:41,  5.99s/file, reading organizations.csv]\u001b[A\n",
      "  organizations:   0%|                                                                | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  organizations:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                   | 1/4 [00:00<00:00, 333.15step/s, loaded]\u001b[A\n",
      "  organizations:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 2/4 [00:00<00:00, 499.92step/s, sampled n=281]\u001b[A\n",
      "  organizations:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 3/4 [00:00<00:00, 125.00step/s, converted rows=2810]\u001b[A\n",
      "  organizations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 114.28step/s, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 11/18 [02:58<00:41,  5.99s/file, reading patients.csv]\u001b[A\n",
      "  patients:   0%|                                                                     | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  patients:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                       | 1/4 [00:00<00:00, 499.92step/s, loaded]\u001b[A\n",
      "  patients:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 2/4 [00:00<00:00, 666.50step/s, sampled n=111]\u001b[A\n",
      "  patients:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 3/4 [00:00<00:00, 37.97step/s, converted rows=2997]\u001b[A\n",
      "  patients: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 44.44step/s, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 13/18 [02:58<00:16,  3.23s/file, reading payer_transitions.csv]\u001b[A\n",
      "  payer_transitions:   0%|                                                            | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  payer_transitions:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                | 1/4 [00:00<00:00, 249.93step/s, loaded]\u001b[A\n",
      "  payer_transitions:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 2/4 [00:00<00:00, 400.05step/s, sampled n=1130]\u001b[A\n",
      "  payer_transitions:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 3/4 [00:00<00:00,  4.37step/s, sampled n=1130]\u001b[A\n",
      "  payer_transitions:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 3/4 [00:00<00:00,  4.37step/s, converted rows=7910]\u001b[A\n",
      "  payer_transitions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.37step/s, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/18 [02:59<00:10,  2.60s/file, reading payers.csv]\u001b[A\n",
      "  payers:   0%|                                                                       | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  payers:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                       | 1/4 [00:00<00:00, 1002.46step/s, loaded]\u001b[A\n",
      "  payers:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 2/4 [00:00<00:00, 1000.55step/s, sampled n=10]\u001b[A\n",
      "  payers:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 3/4 [00:00<00:00, 300.06step/s, converted rows=220]\u001b[A\n",
      "  payers: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 307.71step/s, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/18 [02:59<00:10,  2.60s/file, reading procedures.csv]\u001b[A\n",
      "  procedures:   0%|                                                                   | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  procedures:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                      | 1/4 [00:00<00:00, 38.47step/s, loaded]\u001b[A\n",
      "  procedures:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 2/4 [00:00<00:00, 74.08step/s, sampled n=17993]\u001b[A\n",
      "  procedures:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 3/4 [00:11<00:03,  3.69s/step, sampled n=17993]\u001b[A\n",
      "  procedures:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 3/4 [00:11<00:03,  3.69s/step, converted rows=143944]\u001b[A\n",
      "  procedures: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:11<00:00,  2.64s/step, converted rows=143944]\u001b[A\n",
      "  procedures: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:11<00:00,  2.64s/step, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 16/18 [03:10<00:07,  3.92s/file, reading providers.csv]\u001b[A\n",
      "  providers:   0%|                                                                    | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  providers:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                      | 1/4 [00:00<00:00, 333.25step/s, loaded]\u001b[A\n",
      "  providers:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 2/4 [00:00<00:00, 500.01step/s, sampled n=281]\u001b[A\n",
      "  providers:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 3/4 [00:00<00:00, 93.75step/s, converted rows=3372]\u001b[A\n",
      "  providers: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 88.89step/s, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 16/18 [03:10<00:07,  3.92s/file, reading supplies.csv]\u001b[A\n",
      "  supplies:   0%|                                                                     | 0/4 [00:00<?, ?step/s]\u001b[A\n",
      "  supplies:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                       | 1/4 [00:00<00:00, 142.84step/s, loaded]\u001b[A\n",
      "  supplies:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 2/4 [00:00<00:00, 249.97step/s, sampled n=3659]\u001b[A\n",
      "  supplies:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 3/4 [00:00<00:00,  3.29step/s, sampled n=3659]\u001b[A\n",
      "  supplies:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 3/4 [00:00<00:00,  3.29step/s, converted rows=14636]\u001b[A\n",
      "  supplies: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  3.29step/s, saved]\u001b[A\n",
      "ğŸ”„ Converting CSV â†’ QUIQ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [03:11<00:00, 10.66s/file, âœ… supplies.csv (14636 rows)] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ“Š SUMMARY @ 2025-08-25 15:37:24\n",
      "   Output dir: G:/SYNTHEA_NEW\\QUIQ\n",
      "   Total files: 18 | Success: 18 | Fail: 0\n",
      "\n",
      "âœ… Successes:\n",
      "  - allergies.csv                  â†’ rows: 1443\n",
      "  - careplans.csv                  â†’ rows: 2154\n",
      "  - claims.csv                     â†’ rows: 314650\n",
      "  - claims_transactions.csv        â†’ rows: 2989113\n",
      "  - conditions.csv                 â†’ rows: 20700\n",
      "  - devices.csv                    â†’ rows: 3475\n",
      "  - encounters.csv                 â†’ rows: 77012\n",
      "  - imaging_studies.csv            â†’ rows: 90710\n",
      "  - immunizations.csv              â†’ rows: 6196\n",
      "  - medications.csv                â†’ rows: 54186\n",
      "  - observations.csv               â†’ rows: 264468\n",
      "  - organizations.csv              â†’ rows: 2810\n",
      "  - patients.csv                   â†’ rows: 2997\n",
      "  - payer_transitions.csv          â†’ rows: 7910\n",
      "  - payers.csv                     â†’ rows: 220\n",
      "  - procedures.csv                 â†’ rows: 143944\n",
      "  - providers.csv                  â†’ rows: 3372\n",
      "  - supplies.csv                   â†’ rows: 14636\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================\n",
    "# ì„¤ì •\n",
    "# =========================\n",
    "BASE_DIR = r\"G:/SYNTHEA_NEW\"          # í´ë” ë‚´ ëª¨ë“  CSV ìë™ íƒìƒ‰\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"QUIQ\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "USE_SAMPLE = False                     # 10,000ëª… ìƒ˜í”Œë§ ì‚¬ìš© ì—¬ë¶€\n",
    "SAMPLE_N = 10000\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# =========================\n",
    "# ê³µí†µ ì»¬ëŸ¼ / ìœ í‹¸\n",
    "# =========================\n",
    "QUIQ_COLS = [\n",
    "    \"Primary_key\", \"Variable_ID\", \"Original_table_name\", \"Variable_name\", \"Event_date\",\n",
    "    \"Value\", \"Unit\", \"Variable_type\", \"Is_categorical\", \"Recorder\",\n",
    "    \"Recorder_position\", \"Recorder_affiliation\", \"Patient_id\", \"Admission_id\",\n",
    "    \"Ground_truth\", \"Mapping_info_1\", \"Mapping_info_2\"\n",
    "]\n",
    "\n",
    "# ì½”ë“œ ê³„ì—´ ë³€ìˆ˜ëª…(ì´ë¦„ìœ¼ë¡œë„ ê°•ì œ ì ìš©)\n",
    "CODE_LIKE_NAMES = {\n",
    "    \"CODE\",\"REASONCODE\",\"PROCEDURECODE\",\"BODYSITE_CODE\",\"MODALITY_CODE\",\"SOP_CODE\",\n",
    "    \"PROCEDURE_CODE\",\"DIAGNOSIS1\",\"DIAGNOSIS2\",\"DIAGNOSIS3\",\"DIAGNOSIS4\",\n",
    "    \"DIAGNOSIS5\",\"DIAGNOSIS6\",\"DIAGNOSIS7\",\"DIAGNOSIS8\"\n",
    "}\n",
    "\n",
    "# â”€â”€ ê°’ ì •ë¦¬ê¸°: stripë§Œ ì ìš©\n",
    "def strip_only(x):\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    if isinstance(x, (int, float, np.number, pd.Timestamp)):\n",
    "        return x\n",
    "    return str(x).strip()\n",
    "\n",
    "# â”€â”€ timestamp íŒë³„\n",
    "_DATE_REGEXES = [\n",
    "    r\"^\\d{4}-\\d{2}-\\d{2}$\",\n",
    "    r\"^\\d{4}-\\d{2}-\\d{2}[ T]\\d{2}:\\d{2}(:\\d{2})?$\",\n",
    "    r\"^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}Z$\",\n",
    "    r\"^\\d{4}/\\d{2}/\\d{2}$\",\n",
    "    r\"^\\d{2}/\\d{2}/\\d{4}$\",\n",
    "]\n",
    "def looks_like_date_str(s: str) -> bool:\n",
    "    s = s.strip()\n",
    "    if len(s) < 8: return False\n",
    "    for rgx in _DATE_REGEXES:\n",
    "        if re.match(rgx, s): return True\n",
    "    return False\n",
    "\n",
    "def safe_parse_timestamp(s):\n",
    "    try:\n",
    "        ts = pd.to_datetime(s, errors=\"raise\", utc=False, infer_datetime_format=False)\n",
    "        y = getattr(ts, \"year\", None)\n",
    "        if y is not None and 1900 <= int(y) <= 2100:\n",
    "            return ts\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def infer_variable_type(val):\n",
    "    if pd.isna(val): return np.nan\n",
    "    if isinstance(val, pd.Timestamp): return \"timestamp\"\n",
    "    s = str(val).strip()\n",
    "    if looks_like_date_str(s) and safe_parse_timestamp(s) is not None:\n",
    "        return \"timestamp\"\n",
    "    if re.fullmatch(r\"^[+-]?(\\d+(\\.\\d*)?|\\.\\d+)$\", s):\n",
    "        return \"numeric\"\n",
    "    return \"string\"\n",
    "\n",
    "def normalize_vartype(v):\n",
    "    return v if v in [\"numeric\", \"string\", \"timestamp\"] else np.nan\n",
    "\n",
    "def finalize_common_columns(df, table_name, patient_col, admission_col):\n",
    "    df = df.copy()\n",
    "    df[\"Original_table_name\"] = table_name\n",
    "    df[\"Variable_ID\"] = np.nan\n",
    "\n",
    "    for col in [\"Is_categorical\", \"Mapping_info_1\", \"Mapping_info_2\", \"Value\", \"Variable_type\", \"Variable_name\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "\n",
    "    # âœ… ValueëŠ” ë¬´ì¡°ê±´ stripë§Œ\n",
    "    df[\"Value\"] = df[\"Value\"].apply(strip_only)\n",
    "\n",
    "    # íƒ€ì… í‘œì¤€í™”\n",
    "    df[\"Variable_type\"] = df[\"Variable_type\"].apply(normalize_vartype)\n",
    "\n",
    "    mask_valid = ~df[\"Value\"].isna()\n",
    "    mask_na = ~mask_valid\n",
    "\n",
    "    # ì½”ë“œ ê³„ì—´ ê°ì§€\n",
    "    varnames = df[\"Variable_name\"].astype(str)\n",
    "    mask_code_name = mask_valid & varnames.isin(CODE_LIKE_NAMES)\n",
    "    mask_medcode_map = mask_valid & (df[\"Mapping_info_1\"].astype(str) == \"medical_code\")\n",
    "    mask_code_any = mask_code_name | mask_medcode_map\n",
    "\n",
    "    if mask_code_any.any():\n",
    "        df.loc[mask_code_any, \"Variable_type\"] = \"string\"\n",
    "        df.loc[mask_code_any, \"Is_categorical\"] = 1\n",
    "\n",
    "    if len(df) > 0:\n",
    "        idx = mask_na[mask_na].index\n",
    "        if len(idx) > 0:\n",
    "            df.loc[idx, \"Is_categorical\"] = np.nan\n",
    "            df.loc[idx, \"Mapping_info_1\"] = np.nan\n",
    "            df.loc[idx, \"Mapping_info_2\"] = np.nan\n",
    "\n",
    "    # ë²”ì£¼í˜• ì¶”ë¡ \n",
    "    CATEGORICAL_THRESHOLD = 10\n",
    "    df[\"Is_categorical\"] = df[\"Is_categorical\"].astype(\"float\")\n",
    "    to_infer = mask_valid & df[\"Is_categorical\"].isna()\n",
    "    if to_infer.any():\n",
    "        vc = df.loc[mask_valid].groupby(\"Variable_name\")[\"Value\"].nunique(dropna=True)\n",
    "        cat_vars = set(vc[vc <= CATEGORICAL_THRESHOLD].index)\n",
    "        df.loc[to_infer & df[\"Variable_name\"].isin(cat_vars), \"Is_categorical\"] = 1\n",
    "        df.loc[to_infer & (df[\"Variable_type\"] == \"string\"), \"Is_categorical\"] = 1\n",
    "        df.loc[to_infer & df[\"Is_categorical\"].isna(), \"Is_categorical\"] = 0\n",
    "\n",
    "    if patient_col and (patient_col in df.columns):\n",
    "        df[\"Patient_id\"] = df[patient_col]\n",
    "    else:\n",
    "        if \"Patient_id\" not in df.columns:\n",
    "            df[\"Patient_id\"] = np.nan\n",
    "\n",
    "    if admission_col and (admission_col in df.columns):\n",
    "        df[\"Admission_id\"] = df[admission_col]\n",
    "    else:\n",
    "        if \"Admission_id\" not in df.columns:\n",
    "            df[\"Admission_id\"] = np.nan\n",
    "\n",
    "    df[\"Recorder\"] = np.nan\n",
    "    df[\"Recorder_position\"] = np.nan\n",
    "    df[\"Recorder_affiliation\"] = np.nan\n",
    "    df[\"Ground_truth\"] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def melt_generic(df, table_name, exclude_cols, event_date_col, patient_col, admission_col,\n",
    "                 mapping_rules=None, primary_key_start=1):\n",
    "    _df = df.copy()\n",
    "\n",
    "    _df[\"_row_idx\"] = np.arange(len(_df))\n",
    "    _df[\"_row_pk\"] = np.arange(primary_key_start, primary_key_start + len(_df))\n",
    "\n",
    "    event_src = None\n",
    "    if event_date_col and (event_date_col in _df.columns):\n",
    "        event_src = _df[[\"_row_idx\", event_date_col]].rename(columns={event_date_col: \"_event_src\"})\n",
    "\n",
    "    drop_cols = set(exclude_cols or [])\n",
    "    keep_id_cols = []\n",
    "    if patient_col and (patient_col in _df.columns):\n",
    "        keep_id_cols.append(patient_col)\n",
    "    if admission_col and (admission_col in _df.columns):\n",
    "        keep_id_cols.append(admission_col)\n",
    "    keep_id_cols += [\"_row_idx\", \"_row_pk\"]\n",
    "\n",
    "    id_vars = list(dict.fromkeys(keep_id_cols))\n",
    "    value_vars = [c for c in _df.columns if c not in drop_cols and c not in id_vars]\n",
    "\n",
    "    long_df = _df[id_vars + value_vars].melt(\n",
    "        id_vars=id_vars,\n",
    "        value_vars=value_vars,\n",
    "        var_name=\"Variable_name\",\n",
    "        value_name=\"Value\"\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    long_df[\"Primary_key\"] = long_df[\"_row_pk\"].values\n",
    "    long_df[\"Unit\"] = np.nan\n",
    "    long_df[\"Variable_type\"] = long_df[\"Value\"].map(infer_variable_type)\n",
    "\n",
    "    long_df[\"Mapping_info_1\"] = np.nan\n",
    "    long_df[\"Mapping_info_2\"] = np.nan\n",
    "    long_df[\"Is_categorical\"] = np.nan\n",
    "\n",
    "    if mapping_rules:\n",
    "        def _apply_rule(row):\n",
    "            v = row[\"Variable_name\"]\n",
    "            rule = mapping_rules.get(v)\n",
    "            if rule is None:\n",
    "                return (np.nan, np.nan)\n",
    "            return rule(row) if callable(rule) else rule\n",
    "        m = long_df.apply(_apply_rule, axis=1, result_type=\"expand\")\n",
    "        if isinstance(m, pd.DataFrame):\n",
    "            m.columns = [\"Mapping_info_1\", \"Mapping_info_2\"]\n",
    "            long_df[[\"Mapping_info_1\", \"Mapping_info_2\"]] = m.values\n",
    "\n",
    "    long_df[\"Event_date\"] = np.nan\n",
    "    if event_src is not None and \"DESCRIPTION\" in df.columns:\n",
    "        long_df = long_df.merge(event_src, on=\"_row_idx\", how=\"left\")\n",
    "        desc_mask = long_df[\"Variable_name\"].astype(str).eq(\"DESCRIPTION\")\n",
    "        long_df.loc[desc_mask, \"Event_date\"] = long_df.loc[desc_mask, \"_event_src\"]\n",
    "        long_df.drop(columns=[\"_event_src\"], inplace=True)\n",
    "\n",
    "    long_df = finalize_common_columns(\n",
    "        long_df, table_name, patient_col, admission_col\n",
    "    )\n",
    "    long_df = long_df.drop(columns=[\"_row_idx\", \"_row_pk\"], errors=\"ignore\")\n",
    "\n",
    "    long_df = long_df[QUIQ_COLS]\n",
    "    next_pk = primary_key_start + len(_df)\n",
    "    return long_df, next_pk\n",
    "\n",
    "def convert_observations(df, primary_key_start):\n",
    "    _df = df.copy()\n",
    "    n = len(_df)\n",
    "    row_pk = np.arange(primary_key_start, primary_key_start + n)\n",
    "\n",
    "    base_cols = {\n",
    "        \"Original_table_name\": \"observations\",\n",
    "        \"Recorder\": np.nan,\n",
    "        \"Recorder_position\": np.nan,\n",
    "        \"Recorder_affiliation\": np.nan,\n",
    "        \"Ground_truth\": np.nan,\n",
    "        \"Variable_ID\": np.nan,\n",
    "        \"Patient_id\": _df.get(\"PATIENT\"),\n",
    "        \"Admission_id\": _df.get(\"ENCOUNTER\"),\n",
    "    }\n",
    "\n",
    "    vtype_desc = _df.get(\"VALUE\").map(infer_variable_type) if \"VALUE\" in _df.columns else pd.Series(index=_df.index, dtype=object)\n",
    "    if \"TYPE\" in _df.columns:\n",
    "        forced = _df[\"TYPE\"].astype(str).str.lower().eq(\"text\")\n",
    "        vtype_desc = vtype_desc.astype(object)\n",
    "        vtype_desc[forced.fillna(False)] = \"string\"\n",
    "\n",
    "    desc_df = pd.DataFrame({\n",
    "        \"Primary_key\": row_pk,\n",
    "        \"Variable_ID\": base_cols[\"Variable_ID\"],\n",
    "        \"Original_table_name\": base_cols[\"Original_table_name\"],\n",
    "        \"Variable_name\": _df.get(\"DESCRIPTION\"),\n",
    "        \"Event_date\": _df.get(\"DATE\"),\n",
    "        \"Value\": _df.get(\"VALUE\"),\n",
    "        \"Unit\": _df.get(\"UNITS\"),\n",
    "        \"Variable_type\": vtype_desc,\n",
    "        \"Is_categorical\": np.nan,\n",
    "        \"Recorder\": base_cols[\"Recorder\"],\n",
    "        \"Recorder_position\": base_cols[\"Recorder_position\"],\n",
    "        \"Recorder_affiliation\": base_cols[\"Recorder_affiliation\"],\n",
    "        \"Patient_id\": base_cols[\"Patient_id\"],\n",
    "        \"Admission_id\": base_cols[\"Admission_id\"],\n",
    "        \"Ground_truth\": base_cols[\"Ground_truth\"],\n",
    "        \"Mapping_info_1\": np.nan,\n",
    "        \"Mapping_info_2\": np.nan\n",
    "    })\n",
    "\n",
    "    if \"CATEGORY\" in _df.columns:\n",
    "        is_lab = _df[\"CATEGORY\"].astype(str).str.lower().eq(\"laboratory\")\n",
    "        desc_df.loc[is_lab, [\"Mapping_info_1\", \"Mapping_info_2\"]] = [\"event\", \"lab_event\"]\n",
    "        desc_df.loc[~is_lab, [\"Mapping_info_1\", \"Mapping_info_2\"]] = [\"event\", \"chart_event\"]\n",
    "\n",
    "    code_df = pd.DataFrame({\n",
    "        \"Primary_key\": row_pk,\n",
    "        \"Variable_ID\": base_cols[\"Variable_ID\"],\n",
    "        \"Original_table_name\": base_cols[\"Original_table_name\"],\n",
    "        \"Variable_name\": \"CODE\",\n",
    "        \"Event_date\": np.nan,\n",
    "        \"Value\": _df.get(\"CODE\"),\n",
    "        \"Unit\": np.nan,\n",
    "        \"Variable_type\": \"string\",\n",
    "        \"Is_categorical\": 1,\n",
    "        \"Recorder\": base_cols[\"Recorder\"],\n",
    "        \"Recorder_position\": base_cols[\"Recorder_position\"],\n",
    "        \"Recorder_affiliation\": base_cols[\"Recorder_affiliation\"],\n",
    "        \"Patient_id\": base_cols[\"Patient_id\"],\n",
    "        \"Admission_id\": base_cols[\"Admission_id\"],\n",
    "        \"Ground_truth\": base_cols[\"Ground_truth\"],\n",
    "        \"Mapping_info_1\": \"medical_code\",\n",
    "        \"Mapping_info_2\": np.nan\n",
    "    })\n",
    "\n",
    "    category_df = pd.DataFrame({\n",
    "        \"Primary_key\": row_pk,\n",
    "        \"Variable_ID\": base_cols[\"Variable_ID\"],\n",
    "        \"Original_table_name\": base_cols[\"Original_table_name\"],\n",
    "        \"Variable_name\": \"CATEGORY\",\n",
    "        \"Event_date\": np.nan,\n",
    "        \"Value\": _df.get(\"CATEGORY\"),\n",
    "        \"Unit\": np.nan,\n",
    "        \"Variable_type\": \"string\",\n",
    "        \"Is_categorical\": np.nan,\n",
    "        \"Recorder\": base_cols[\"Recorder\"],\n",
    "        \"Recorder_position\": base_cols[\"Recorder_position\"],\n",
    "        \"Recorder_affiliation\": base_cols[\"Recorder_affiliation\"],\n",
    "        \"Patient_id\": base_cols[\"Patient_id\"],\n",
    "        \"Admission_id\": base_cols[\"Admission_id\"],\n",
    "        \"Ground_truth\": base_cols[\"Ground_truth\"],\n",
    "        \"Mapping_info_1\": np.nan,\n",
    "        \"Mapping_info_2\": np.nan\n",
    "    })\n",
    "\n",
    "    out = pd.concat([desc_df, code_df, category_df], ignore_index=True)\n",
    "    out = finalize_common_columns(out, \"observations\", patient_col=None, admission_col=None)\n",
    "    out = out[QUIQ_COLS]\n",
    "    next_pk = primary_key_start + n\n",
    "    return out, next_pk\n",
    "\n",
    "# =========================\n",
    "# í…Œì´ë¸” ìŠ¤í™\n",
    "# =========================\n",
    "TABLE_SPECS = {\n",
    "    \"allergies\": dict(\n",
    "        exclude={\"PATIENT\", \"ENCOUNTER\"},\n",
    "        event_date=\"START\",\n",
    "        patient=\"PATIENT\",\n",
    "        admission=\"ENCOUNTER\",\n",
    "        mapping={\n",
    "            \"CODE\": (\"medical_code\", None),\n",
    "            \"REACTION1\": (\"medical_code\", None),\n",
    "            \"REACTION2\": (\"medical_code\", None),\n",
    "            \"START\": (\"date\", None),\n",
    "            \"STOP\": (\"date\", None),\n",
    "            \"DESCRIPTION\": (\"diagnosis\", None),\n",
    "            \"DESCRIPTION1\": (\"diagnosis\", None),\n",
    "            \"DESCRIPTION2\": (\"diagnosis\", None),\n",
    "        }\n",
    "    ),\n",
    "    \"careplans\": dict(\n",
    "        exclude={\"Id\", \"PATIENT\", \"ENCOUNTER\"},\n",
    "        event_date=\"START\",\n",
    "        patient=\"PATIENT\",\n",
    "        admission=\"ENCOUNTER\",\n",
    "        mapping={\n",
    "            \"CODE\": (\"medical_code\", None),\n",
    "            \"REASONCODE\": (\"medical_code\", None),\n",
    "            \"START\": (\"date\", None),\n",
    "            \"STOP\": (\"date\", None),\n",
    "            \"DESCRIPTION\": (\"procedure\", None),\n",
    "            \"REASONDESCRIPTION\": (\"diagnosis\", None),\n",
    "        }\n",
    "    ),\n",
    "    \"claims\": dict(\n",
    "        exclude={\"Id\", \"PATIENTID\"},\n",
    "        event_date=\"SERVICEDATE\",\n",
    "        patient=\"PATIENTID\",\n",
    "        admission=None,\n",
    "        mapping={**{f\"DIAGNOSIS{i}\": (\"medical_code\", None) for i in range(1, 9)},\n",
    "                 **{k: (\"date\", None) for k in [\"CURRENTILLNESSDATE\",\"SERVICEDATE\",\"LASTBILLEDDATE1\",\"LASTBILLEDDATE2\",\"LASTBILLEDDATEP\"]}}\n",
    "    ),\n",
    "    \"claims_transactions\": dict(\n",
    "        exclude={\"ID\", \"PATIENTID\"},\n",
    "        event_date=\"FROMDATE\",\n",
    "        patient=\"PATIENTID\",\n",
    "        admission=None,\n",
    "        mapping={\n",
    "            \"PROCEDURECODE\": (\"medical_code\", None),\n",
    "            \"FROMDATE\": (\"date\", None),\n",
    "            \"TODATE\": (\"date\", None),\n",
    "        }\n",
    "    ),\n",
    "    \"conditions\": dict(\n",
    "        exclude={\"PATIENT\", \"ENCOUNTER\"},\n",
    "        event_date=\"START\",\n",
    "        patient=\"PATIENT\",\n",
    "        admission=\"ENCOUNTER\",\n",
    "        mapping={\n",
    "            \"CODE\": (\"medical_code\", None),\n",
    "            \"START\": (\"date\", None),\n",
    "            \"STOP\": (\"date\", None),\n",
    "            \"DESCRIPTION\": (\"event\", \"chart_event\"),\n",
    "        }\n",
    "    ),\n",
    "    \"devices\": dict(\n",
    "        exclude={\"PATIENT\", \"ENCOUNTER\"},\n",
    "        event_date=\"START\",\n",
    "        patient=\"PATIENT\",\n",
    "        admission=\"ENCOUNTER\",\n",
    "        mapping={\n",
    "            \"CODE\": (\"medical_code\", None),\n",
    "            \"START\": (\"date\", None),\n",
    "            \"STOP\": (\"date\", None),\n",
    "        }\n",
    "    ),\n",
    "    \"encounters\": dict(\n",
    "        exclude={\"Id\", \"PATIENT\", \"ENCOUNTER\"},\n",
    "        event_date=\"START\",\n",
    "        patient=\"PATIENT\",\n",
    "        admission=\"ENCOUNTER\",\n",
    "        mapping={\n",
    "            \"CODE\": (\"medical_code\", None),\n",
    "            \"REASONCODE\": (\"medical_code\", None),\n",
    "            \"START\": (\"date\", None),\n",
    "            \"STOP\": (\"date\", None),\n",
    "            \"REASONDESCRIPTION\": (\"diagnosis\", None),\n",
    "        }\n",
    "    ),\n",
    "    \"imaging_studies\": dict(\n",
    "        exclude={\"Id\", \"PATIENT\", \"ENCOUNTER\"},\n",
    "        event_date=\"DATE\",\n",
    "        patient=\"PATIENT\",\n",
    "        admission=\"ENCOUNTER\",\n",
    "        mapping={\n",
    "            \"PROCEDURE_CODE\": (\"medical_code\", None),\n",
    "            \"BODYSITE_CODE\": (\"medical_code\", None),\n",
    "        }\n",
    "    ),\n",
    "    \"immunizations\": dict(\n",
    "        exclude={\"PATIENT\", \"ENCOUNTER\"},\n",
    "        event_date=\"DATE\",\n",
    "        patient=\"PATIENT\",\n",
    "        admission=None,\n",
    "        mapping={\n",
    "            \"CODE\": (\"medical_code\", None),\n",
    "            \"DESCRIPTION\": (\"prescription\", \"drug\"),\n",
    "        }\n",
    "    ),\n",
    "    \"medications\": dict(\n",
    "        exclude={\"PATIENT\", \"ENCOUNTER\"},\n",
    "        event_date=\"START\",\n",
    "        patient=\"PATIENT\",\n",
    "        admission=\"ENCOUNTER\",\n",
    "        mapping={\n",
    "            \"CODE\": (\"medical_code\", None),\n",
    "            \"REASONCODE\": (\"medical_code\", None),\n",
    "            \"START\": (\"date\", None),\n",
    "            \"STOP\": (\"date\", None),\n",
    "            \"DESCRIPTION\": (\"prescription\", \"drug\"),\n",
    "            \"REASONDESCRIPTION\": (\"diagnosis\", None),\n",
    "        }\n",
    "    ),\n",
    "    \"observations\": dict(_custom=\"observations\"),\n",
    "    \"organizations\": dict(\n",
    "        exclude={\"Id\"},\n",
    "        event_date=None,\n",
    "        patient=\"Id\",\n",
    "        admission=None,\n",
    "        mapping={}\n",
    "    ),\n",
    "    \"patients\": dict(\n",
    "        exclude={\"Id\"},\n",
    "        event_date=None,\n",
    "        patient=\"Id\",\n",
    "        admission=None,\n",
    "        mapping={\n",
    "            \"BIRTHDATE\": (\"date\", None),\n",
    "            \"DEATHDATE\": (\"date\", None),\n",
    "        }\n",
    "    ),\n",
    "    \"payers\": dict(\n",
    "        exclude=set(),\n",
    "        event_date=None,\n",
    "        patient=None,\n",
    "        admission=None,\n",
    "        mapping={}\n",
    "    ),\n",
    "    \"payer_transitions\": dict(\n",
    "        exclude={\"PATIENT\"},\n",
    "        event_date=None,\n",
    "        patient=\"PATIENT\",\n",
    "        admission=\"ENCOUNTER\",\n",
    "        mapping={\n",
    "            \"START_DATE\": (\"date\", None),\n",
    "            \"END_DATE\": (\"date\", None),\n",
    "        }\n",
    "    ),\n",
    "    \"procedures\": dict(\n",
    "        exclude={\"PATIENT\", \"ENCOUNTER\"},\n",
    "        event_date=\"START\",\n",
    "        patient=\"PATIENT\",\n",
    "        admission=\"ENCOUNTER\",\n",
    "        mapping={\n",
    "            \"CODE\": (\"medical_code\", None),\n",
    "            \"REASONCODE\": (\"medical_code\", None),\n",
    "            \"START\": (\"date\", None),\n",
    "            \"STOP\": (\"date\", None),\n",
    "            \"DESCRIPTION\": (\"procedure\", None),\n",
    "            \"REASONDESCRIPTION\": (\"diagnosis\", None),\n",
    "        }\n",
    "    ),\n",
    "    \"providers\": dict(\n",
    "        exclude={\"Id\"},\n",
    "        event_date=None,\n",
    "        patient=\"Id\",\n",
    "        admission=None,\n",
    "        mapping={}\n",
    "    ),\n",
    "    \"supplies\": dict(\n",
    "        exclude={\"PATIENT\", \"ENCOUNTER\"},\n",
    "        event_date=\"DATE\",\n",
    "        patient=\"PATIENT\",\n",
    "        admission=\"ENCOUNTER\",\n",
    "        mapping={\n",
    "            \"CODE\": (\"medical_code\", None),\n",
    "        }\n",
    "    ),\n",
    "}\n",
    "\n",
    "def apply_custom_claims_tx_mappings(df):\n",
    "    def note_mapper(row):\n",
    "        v = row[\"Variable_name\"]\n",
    "        if v in [\"NOTES\", \"LINENOTE\"]:\n",
    "            val = row[\"Value\"]\n",
    "            if isinstance(val, str) and (\"(\" in val and \")\" in val):\n",
    "                return (\"procedure\", None)\n",
    "            return (\"prescription\", \"drug\")\n",
    "        return (row[\"Mapping_info_1\"], row[\"Mapping_info_2\"])\n",
    "    m = df.apply(note_mapper, axis=1, result_type=\"expand\")\n",
    "    if isinstance(m, pd.DataFrame):\n",
    "        m.columns = [\"Mapping_info_1\", \"Mapping_info_2\"]\n",
    "        df[[\"Mapping_info_1\", \"Mapping_info_2\"]] = m.values\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# ìƒ˜í”Œë§ ì¤€ë¹„\n",
    "# =========================\n",
    "sample_patient_ids = None\n",
    "if USE_SAMPLE:\n",
    "    patient_csv = None\n",
    "    for nm in [\"patients.csv\", \"Patients.csv\", \"PATIENTS.csv\"]:\n",
    "        p = os.path.join(BASE_DIR, nm)\n",
    "        if os.path.exists(p):\n",
    "            patient_csv = p\n",
    "            break\n",
    "    if patient_csv:\n",
    "        pdf = pd.read_csv(patient_csv, low_memory=False)\n",
    "        id_col = \"Id\" if \"Id\" in pdf.columns else (\"ID\" if \"ID\" in pdf.columns else None)\n",
    "        if id_col:\n",
    "            cand = pdf[id_col].dropna().drop_duplicates().astype(str)\n",
    "            if len(cand) > SAMPLE_N:\n",
    "                cand = cand.sample(n=SAMPLE_N, random_state=RANDOM_SEED)\n",
    "            sample_patient_ids = set(cand)\n",
    "\n",
    "def apply_sampling(df):\n",
    "    \"\"\"\n",
    "    âœ… ìƒ˜í”Œë§ì€ ì˜¤ì§ í™˜ì ì‹ë³„ ì»¬ëŸ¼ì—ì„œë§Œ ì ìš©:\n",
    "       - PATIENT / PATIENTID ë§Œ í•„í„°\n",
    "       - 'Id'ëŠ” í™˜ìí…Œì´ë¸”ì´ ì•„ë‹Œ ê³³ì—ì„œëŠ” í•„í„°í•˜ì§€ ì•ŠìŒ\n",
    "    \"\"\"\n",
    "    if not USE_SAMPLE or sample_patient_ids is None:\n",
    "        return df\n",
    "    _df = df.copy()\n",
    "    if \"PATIENT\" in _df.columns:\n",
    "        return _df[_df[\"PATIENT\"].astype(str).isin(sample_patient_ids)]\n",
    "    if \"PATIENTID\" in _df.columns:\n",
    "        return _df[_df[\"PATIENTID\"].astype(str).isin(sample_patient_ids)]\n",
    "    return _df  # ê·¸ ì™¸ í…Œì´ë¸”ì€ ìƒ˜í”Œë§ ê±´ë„ˆëœ€\n",
    "\n",
    "# =========================\n",
    "# ë©”ì¸ ë£¨í”„ (tqdm ì§„í–‰ë°”)\n",
    "# =========================\n",
    "def run():\n",
    "    global_pk = 1\n",
    "    successes, failures = [], []\n",
    "\n",
    "    csv_files = sorted(glob.glob(os.path.join(BASE_DIR, \"*.csv\")))\n",
    "    if not csv_files:\n",
    "        print(\"âš ï¸ No CSV files found in:\", BASE_DIR)\n",
    "        return\n",
    "\n",
    "    pbar_files = tqdm(csv_files, desc=\"ğŸ”„ Converting CSV â†’ QUIQ\", unit=\"file\")\n",
    "\n",
    "    for fp in pbar_files:\n",
    "        filename = os.path.basename(fp)\n",
    "        table = filename[:-4].lower() if filename.lower().endswith(\".csv\") else filename.lower()\n",
    "        pbar_files.set_postfix_str(f\"reading {filename}\")\n",
    "\n",
    "        try:\n",
    "            with tqdm(total=4, desc=f\"  {table}\", leave=False, unit=\"step\") as pbar_step:\n",
    "                # 1) ì½ê¸°\n",
    "                df = pd.read_csv(fp, low_memory=False)\n",
    "                pbar_step.update(1); pbar_step.set_postfix_str(\"loaded\")\n",
    "\n",
    "                # 2) ìƒ˜í”Œë§\n",
    "                df = apply_sampling(df)\n",
    "                pbar_step.update(1); pbar_step.set_postfix_str(f\"sampled n={len(df)}\")\n",
    "\n",
    "                # 3) ë³€í™˜\n",
    "                spec = TABLE_SPECS.get(table, None)\n",
    "\n",
    "                if table == \"observations\":\n",
    "                    out_df, global_pk = convert_observations(df, global_pk)\n",
    "                else:\n",
    "                    if not spec:\n",
    "                        patient_col = \"PATIENT\" if \"PATIENT\" in df.columns else (\n",
    "                            \"PATIENTID\" if \"PATIENTID\" in df.columns else None\n",
    "                        )\n",
    "                        admission_col = \"ENCOUNTER\" if \"ENCOUNTER\" in df.columns else None\n",
    "                        out_df, global_pk = melt_generic(\n",
    "                            df=df, table_name=table,\n",
    "                            exclude_cols=set(),\n",
    "                            event_date_col=None,\n",
    "                            patient_col=patient_col,\n",
    "                            admission_col=admission_col,\n",
    "                            mapping_rules={},\n",
    "                            primary_key_start=global_pk\n",
    "                        )\n",
    "                    else:\n",
    "                        mapping_rules = dict(spec.get(\"mapping\", {}))\n",
    "                        out_df, global_pk = melt_generic(\n",
    "                            df=df, table_name=table,\n",
    "                            exclude_cols=spec.get(\"exclude\", set()),\n",
    "                            event_date_col=spec.get(\"event_date\"),\n",
    "                            patient_col=spec.get(\"patient\"),\n",
    "                            admission_col=spec.get(\"admission\"),\n",
    "                            mapping_rules=mapping_rules,\n",
    "                            primary_key_start=global_pk\n",
    "                        )\n",
    "                        if table == \"claims_transactions\":\n",
    "                            out_df = apply_custom_claims_tx_mappings(out_df)\n",
    "\n",
    "                pbar_step.update(1); pbar_step.set_postfix_str(f\"converted rows={len(out_df)}\")\n",
    "\n",
    "                # 4) ì €ì¥\n",
    "                out_path = os.path.join(OUTPUT_DIR, f\"{table}_QUIQ.csv\")\n",
    "                out_df = out_df[QUIQ_COLS]\n",
    "                out_df.to_csv(out_path, index=False)\n",
    "                pbar_step.update(1); pbar_step.set_postfix_str(\"saved\")\n",
    "\n",
    "            successes.append((filename, len(out_df)))\n",
    "            pbar_files.set_postfix_str(f\"âœ… {filename} ({len(out_df)} rows)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            failures.append((filename, str(e)))\n",
    "            pbar_files.set_postfix_str(f\"âŒ {filename} error\")\n",
    "            tqdm.write(f\"âŒ Error in {filename}: {e}\")\n",
    "\n",
    "    # ìš”ì•½\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"ğŸ“Š SUMMARY @ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"   Output dir: {OUTPUT_DIR}\")\n",
    "    print(f\"   Total files: {len(csv_files)} | Success: {len(successes)} | Fail: {len(failures)}\")\n",
    "    if successes:\n",
    "        print(\"\\nâœ… Successes:\")\n",
    "        for name, n in successes:\n",
    "            print(f\"  - {name:30s} â†’ rows: {n}\")\n",
    "    if failures:\n",
    "        print(\"\\nâŒ Failures:\")\n",
    "        for name, msg in failures:\n",
    "            print(f\"  - {name:30s} â†’ {msg}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7ef100",
   "metadata": {},
   "source": [
    "# VIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "029e6d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… VIA_table.csv created with exactly these columns: Original_table_name, Variable_name, Description\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_table_name</th>\n",
       "      <th>Variable_name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allergies</td>\n",
       "      <td>CODE</td>\n",
       "      <td>Standard code (diagnosis, procedure, encounter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allergies</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "      <td>Textual description of the code or record.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allergies</td>\n",
       "      <td>START</td>\n",
       "      <td>Start date/time of condition, allergy, or plan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allergies</td>\n",
       "      <td>STOP</td>\n",
       "      <td>End date/time of condition, allergy, or plan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>careplans</td>\n",
       "      <td>CODE</td>\n",
       "      <td>Standard code (diagnosis, procedure, encounter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>careplans</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "      <td>Textual description of the code or record.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>careplans</td>\n",
       "      <td>REASONCODE</td>\n",
       "      <td>Code indicating the reason for the event/proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>careplans</td>\n",
       "      <td>REASONDESCRIPTION</td>\n",
       "      <td>Text description of the reason for the event/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>careplans</td>\n",
       "      <td>START</td>\n",
       "      <td>Start date/time of condition, allergy, or plan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>careplans</td>\n",
       "      <td>STOP</td>\n",
       "      <td>End date/time of condition, allergy, or plan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>conditions</td>\n",
       "      <td>CODE</td>\n",
       "      <td>Standard code (diagnosis, procedure, encounter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>conditions</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "      <td>Textual description of the code or record.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>conditions</td>\n",
       "      <td>START</td>\n",
       "      <td>Start date/time of condition, allergy, or plan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>conditions</td>\n",
       "      <td>STOP</td>\n",
       "      <td>End date/time of condition, allergy, or plan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>encounters</td>\n",
       "      <td>CODE</td>\n",
       "      <td>Standard code (diagnosis, procedure, encounter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>encounters</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Event date.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>encounters</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "      <td>Textual description of the code or record.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>encounters</td>\n",
       "      <td>REASONCODE</td>\n",
       "      <td>Code indicating the reason for the event/proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>encounters</td>\n",
       "      <td>REASONDESCRIPTION</td>\n",
       "      <td>Text description of the reason for the event/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>immunizations</td>\n",
       "      <td>CODE</td>\n",
       "      <td>Standard code (diagnosis, procedure, encounter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>immunizations</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Event date.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>immunizations</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "      <td>Textual description of the code or record.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>medications</td>\n",
       "      <td>CODE</td>\n",
       "      <td>Standard code (diagnosis, procedure, encounter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>medications</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Event date.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>medications</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "      <td>Textual description of the code or record.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>observations</td>\n",
       "      <td>CODE</td>\n",
       "      <td>Standard code (diagnosis, procedure, encounter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>observations</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Event date.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>observations</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "      <td>Textual description of the code or record.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>observations</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>Observed or measured value.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>patients</td>\n",
       "      <td>ADDRESS</td>\n",
       "      <td>Address (masked).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>patients</td>\n",
       "      <td>BIRTHDATE</td>\n",
       "      <td>Patientâ€™s birth date.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>patients</td>\n",
       "      <td>BIRTHPLACE</td>\n",
       "      <td>Place of birth.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>patients</td>\n",
       "      <td>DEATHDATE</td>\n",
       "      <td>Patientâ€™s death date (if applicable).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>patients</td>\n",
       "      <td>DRIVERS</td>\n",
       "      <td>Driverâ€™s license number (masked).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>patients</td>\n",
       "      <td>ETHNICITY</td>\n",
       "      <td>Ethnicity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>patients</td>\n",
       "      <td>FIRST</td>\n",
       "      <td>First/given name.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>patients</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>Gender.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>patients</td>\n",
       "      <td>LAST</td>\n",
       "      <td>Last/family name.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>patients</td>\n",
       "      <td>MAIDEN</td>\n",
       "      <td>Maiden name.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>patients</td>\n",
       "      <td>MARITAL</td>\n",
       "      <td>Marital status.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>patients</td>\n",
       "      <td>PASSPORT</td>\n",
       "      <td>Passport number (masked).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>patients</td>\n",
       "      <td>PREFIX</td>\n",
       "      <td>Name prefix (e.g., Mr, Dr).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>patients</td>\n",
       "      <td>RACE</td>\n",
       "      <td>Race.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>patients</td>\n",
       "      <td>SSN</td>\n",
       "      <td>Social Security Number (masked).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>patients</td>\n",
       "      <td>SUFFIX</td>\n",
       "      <td>Name suffix (e.g., Jr, Sr).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>procedures</td>\n",
       "      <td>CODE</td>\n",
       "      <td>Standard code (diagnosis, procedure, encounter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>procedures</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Event date.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>procedures</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "      <td>Textual description of the code or record.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>procedures</td>\n",
       "      <td>REASONCODE</td>\n",
       "      <td>Code indicating the reason for the event/proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>procedures</td>\n",
       "      <td>REASONDESCRIPTION</td>\n",
       "      <td>Text description of the reason for the event/p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Original_table_name      Variable_name  \\\n",
       "0            allergies               CODE   \n",
       "1            allergies        DESCRIPTION   \n",
       "2            allergies              START   \n",
       "3            allergies               STOP   \n",
       "4            careplans               CODE   \n",
       "5            careplans        DESCRIPTION   \n",
       "6            careplans         REASONCODE   \n",
       "7            careplans  REASONDESCRIPTION   \n",
       "8            careplans              START   \n",
       "9            careplans               STOP   \n",
       "10          conditions               CODE   \n",
       "11          conditions        DESCRIPTION   \n",
       "12          conditions              START   \n",
       "13          conditions               STOP   \n",
       "14          encounters               CODE   \n",
       "15          encounters               DATE   \n",
       "16          encounters        DESCRIPTION   \n",
       "17          encounters         REASONCODE   \n",
       "18          encounters  REASONDESCRIPTION   \n",
       "19       immunizations               CODE   \n",
       "20       immunizations               DATE   \n",
       "21       immunizations        DESCRIPTION   \n",
       "22         medications               CODE   \n",
       "23         medications               DATE   \n",
       "24         medications        DESCRIPTION   \n",
       "25        observations               CODE   \n",
       "26        observations               DATE   \n",
       "27        observations        DESCRIPTION   \n",
       "28        observations              VALUE   \n",
       "29            patients            ADDRESS   \n",
       "30            patients          BIRTHDATE   \n",
       "31            patients         BIRTHPLACE   \n",
       "32            patients          DEATHDATE   \n",
       "33            patients            DRIVERS   \n",
       "34            patients          ETHNICITY   \n",
       "35            patients              FIRST   \n",
       "36            patients             GENDER   \n",
       "37            patients               LAST   \n",
       "38            patients             MAIDEN   \n",
       "39            patients            MARITAL   \n",
       "40            patients           PASSPORT   \n",
       "41            patients             PREFIX   \n",
       "42            patients               RACE   \n",
       "43            patients                SSN   \n",
       "44            patients             SUFFIX   \n",
       "45          procedures               CODE   \n",
       "46          procedures               DATE   \n",
       "47          procedures        DESCRIPTION   \n",
       "48          procedures         REASONCODE   \n",
       "49          procedures  REASONDESCRIPTION   \n",
       "\n",
       "                                          Description  \n",
       "0   Standard code (diagnosis, procedure, encounter...  \n",
       "1          Textual description of the code or record.  \n",
       "2     Start date/time of condition, allergy, or plan.  \n",
       "3       End date/time of condition, allergy, or plan.  \n",
       "4   Standard code (diagnosis, procedure, encounter...  \n",
       "5          Textual description of the code or record.  \n",
       "6   Code indicating the reason for the event/proce...  \n",
       "7   Text description of the reason for the event/p...  \n",
       "8     Start date/time of condition, allergy, or plan.  \n",
       "9       End date/time of condition, allergy, or plan.  \n",
       "10  Standard code (diagnosis, procedure, encounter...  \n",
       "11         Textual description of the code or record.  \n",
       "12    Start date/time of condition, allergy, or plan.  \n",
       "13      End date/time of condition, allergy, or plan.  \n",
       "14  Standard code (diagnosis, procedure, encounter...  \n",
       "15                                        Event date.  \n",
       "16         Textual description of the code or record.  \n",
       "17  Code indicating the reason for the event/proce...  \n",
       "18  Text description of the reason for the event/p...  \n",
       "19  Standard code (diagnosis, procedure, encounter...  \n",
       "20                                        Event date.  \n",
       "21         Textual description of the code or record.  \n",
       "22  Standard code (diagnosis, procedure, encounter...  \n",
       "23                                        Event date.  \n",
       "24         Textual description of the code or record.  \n",
       "25  Standard code (diagnosis, procedure, encounter...  \n",
       "26                                        Event date.  \n",
       "27         Textual description of the code or record.  \n",
       "28                        Observed or measured value.  \n",
       "29                                  Address (masked).  \n",
       "30                              Patientâ€™s birth date.  \n",
       "31                                    Place of birth.  \n",
       "32              Patientâ€™s death date (if applicable).  \n",
       "33                  Driverâ€™s license number (masked).  \n",
       "34                                         Ethnicity.  \n",
       "35                                  First/given name.  \n",
       "36                                            Gender.  \n",
       "37                                  Last/family name.  \n",
       "38                                       Maiden name.  \n",
       "39                                    Marital status.  \n",
       "40                          Passport number (masked).  \n",
       "41                        Name prefix (e.g., Mr, Dr).  \n",
       "42                                              Race.  \n",
       "43                   Social Security Number (masked).  \n",
       "44                        Name suffix (e.g., Jr, Sr).  \n",
       "45  Standard code (diagnosis, procedure, encounter...  \n",
       "46                                        Event date.  \n",
       "47         Textual description of the code or record.  \n",
       "48  Code indicating the reason for the event/proce...  \n",
       "49  Text description of the reason for the event/p...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ===============================================\n",
    "# 1) Source CSV schemas (exactly as you provided)\n",
    "# ===============================================\n",
    "schema = {\n",
    "    \"allergies\":      [\"START\",\"STOP\",\"CODE\",\"DESCRIPTION\"],\n",
    "    \"careplans\":      [\"START\",\"STOP\",\"CODE\",\"DESCRIPTION\",\"REASONCODE\",\"REASONDESCRIPTION\"],\n",
    "    \"conditions\":     [\"START\",\"STOP\",\"CODE\",\"DESCRIPTION\"],\n",
    "    \"encounters\":     [\"DATE\",\"CODE\",\"DESCRIPTION\",\"REASONCODE\",\"REASONDESCRIPTION\"],\n",
    "    \"immunizations\":  [\"DATE\",\"CODE\",\"DESCRIPTION\"],\n",
    "    \"medications\":    [\"DATE\",\"CODE\",\"DESCRIPTION\"],\n",
    "    \"observations\":   [\"DATE\",\"CODE\",\"DESCRIPTION\",\"VALUE\"],\n",
    "    \"patients\":       [\"BIRTHDATE\",\"DEATHDATE\",\"SSN\",\"DRIVERS\",\"PASSPORT\",\"PREFIX\",\"FIRST\",\"LAST\",\"SUFFIX\",\n",
    "                       \"MAIDEN\",\"MARITAL\",\"RACE\",\"ETHNICITY\",\"GENDER\",\"BIRTHPLACE\",\"ADDRESS\"],\n",
    "    \"procedures\":     [\"DATE\",\"CODE\",\"DESCRIPTION\",\"REASONCODE\",\"REASONDESCRIPTION\"],\n",
    "}\n",
    "\n",
    "# ===============================================\n",
    "# 2) Column name â†’ Description (English)\n",
    "# ===============================================\n",
    "variable_desc = {\n",
    "    # Generic fields\n",
    "    \"START\": \"Start date/time of condition, allergy, or plan.\",\n",
    "    \"STOP\": \"End date/time of condition, allergy, or plan.\",\n",
    "    \"DATE\": \"Event date.\",\n",
    "    \"CODE\": \"Standard code (diagnosis, procedure, encounter, etc.).\",\n",
    "    \"DESCRIPTION\": \"Textual description of the code or record.\",\n",
    "    \"REASONCODE\": \"Code indicating the reason for the event/procedure.\",\n",
    "    \"REASONDESCRIPTION\": \"Text description of the reason for the event/procedure.\",\n",
    "    \"VALUE\": \"Observed or measured value.\",\n",
    "\n",
    "    # Patient-specific\n",
    "    \"BIRTHDATE\": \"Patientâ€™s birth date.\",\n",
    "    \"DEATHDATE\": \"Patientâ€™s death date (if applicable).\",\n",
    "    \"SSN\": \"Social Security Number (masked).\",\n",
    "    \"DRIVERS\": \"Driverâ€™s license number (masked).\",\n",
    "    \"PASSPORT\": \"Passport number (masked).\",\n",
    "    \"PREFIX\": \"Name prefix (e.g., Mr, Dr).\",\n",
    "    \"FIRST\": \"First/given name.\",\n",
    "    \"LAST\": \"Last/family name.\",\n",
    "    \"SUFFIX\": \"Name suffix (e.g., Jr, Sr).\",\n",
    "    \"MAIDEN\": \"Maiden name.\",\n",
    "    \"MARITAL\": \"Marital status.\",\n",
    "    \"RACE\": \"Race.\",\n",
    "    \"ETHNICITY\": \"Ethnicity.\",\n",
    "    \"GENDER\": \"Gender.\",\n",
    "    \"BIRTHPLACE\": \"Place of birth.\",\n",
    "    \"ADDRESS\": \"Address (masked).\",\n",
    "}\n",
    "\n",
    "# ===============================================\n",
    "# 3) Build VIA table (Original_table_name + Column + Description)\n",
    "# ===============================================\n",
    "rows = []\n",
    "for table, cols in schema.items():\n",
    "    for col in cols:\n",
    "        desc = variable_desc.get(col, None)  # leave blank if not in dict\n",
    "        rows.append({\n",
    "            \"Original_table_name\": table,\n",
    "            \"Variable_name\": col,\n",
    "            \"Description\": desc\n",
    "        })\n",
    "\n",
    "via = (\n",
    "    pd.DataFrame(rows)\n",
    "    .drop_duplicates()\n",
    "    .sort_values([\"Original_table_name\", \"Variable_name\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Save\n",
    "\n",
    "via.to_csv(\"VIA_table.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"âœ… VIA_table.csv created with exactly these columns: Original_table_name, Variable_name, Description\")\n",
    "via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53868bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# CSVë“¤ì´ ë“¤ì–´ìˆëŠ” í´ë” ê²½ë¡œ\n",
    "folder_path = r\"G:\\SYNTHEA_NEW\\QUIQ\"\n",
    "\n",
    "# í´ë” ì•ˆì˜ ëª¨ë“  csv íŒŒì¼ ê²½ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "all_csv_files = glob.glob(os.path.join(folder_path, \"*_QUIQ.csv\"))\n",
    "\n",
    "# ê° íŒŒì¼ì„ ì½ì–´ì„œ ë¦¬ìŠ¤íŠ¸ì— ë‹´ê¸°\n",
    "dfs = []\n",
    "for file in all_csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# í•˜ë‚˜ë¡œ í•©ì¹˜ê¸° (í–‰ ë°©í–¥ìœ¼ë¡œ ì´ì–´ë¶™ì´ê¸°)\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "merged_df = merged_df.astype(str).replace('\\u2013', '-', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30e31191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV í•©ì¹˜ê¸° ì™„ë£Œ! -> merged.csv\n"
     ]
    }
   ],
   "source": [
    "# ì €ì¥í•˜ê¸°\n",
    "merged_df.to_csv(os.path.join(folder_path, \"merged.csv\"), index=False)\n",
    "print(\"CSV í•©ì¹˜ê¸° ì™„ë£Œ! -> merged.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
